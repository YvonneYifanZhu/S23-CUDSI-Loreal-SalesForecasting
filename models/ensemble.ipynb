{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Astron/Desktop/L_Oreal/S23-CUDSI-Loreal-SalesForecasting/traffic_cleaned_forPython_k.csv\", parse_dates=['day'])\n",
    "data.set_index('day', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "### One hot encoding\n",
    "data = pd.get_dummies(data, dtype=\"bool\")\n",
    "data = data.astype('int')\n",
    "\n",
    "### To aviod \"Do not support special JSON characters in feature name\" error in LightGBM\n",
    "import re\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "data_trans = data.reset_index()\n",
    "\n",
    "data_trans['y'] = data_trans.day.dt.year\n",
    "data_trans['m'] = data_trans.day.dt.month\n",
    "data_trans['d'] = data_trans.day.dt.day\n",
    "\n",
    "data_sincos = encode(data_trans, 'm', 12)\n",
    "data_sincos = encode(data_trans, 'd', 31)\n",
    "data_sincos.set_index('day', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_sincos.drop(columns = ['CORE_VL_NbEntry'])\n",
    "y = data_sincos['CORE_VL_NbEntry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "MSE: 11.331326308611292\n",
      "xgb_r^2: 0.8757338123941485\n",
      "11.331326308611292\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning\n",
    "#XGboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#construct grids for hyperparameter tunning\n",
    "param_grid_XGB = {'n_estimators':[100], \n",
    "                  'max_depth': [12], \n",
    "                  'learning_rate': [0.1]}\n",
    "\n",
    "grid_XGB = GridSearchCV(XGBRegressor(), param_grid_XGB, refit = True, cv = 5, verbose = 3, n_jobs=-1) \n",
    "grid_XGB.fit(X_dev, y_dev)\n",
    "\n",
    "#accuracy check\n",
    "\n",
    "xgbc = XGBRegressor(learning_rate=grid_XGB.best_params_['learning_rate'], \n",
    "                                      max_depth = grid_XGB.best_params_['max_depth'], \n",
    "                                      n_estimators = grid_XGB.best_params_['n_estimators']).fit(X_train, y_train)\n",
    "\n",
    "xgbc_y_test = xgbc.predict(X_test)\n",
    "\n",
    "print('MSE:', np.sqrt(mean_squared_error(y_test, xgbc_y_test)))\n",
    "print('xgb_r^2:', xgbc.score(X_test, y_test))\n",
    "print(np.sqrt(mean_squared_error(y_test, xgbc_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# ! Don't Run!!!!\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid_rf = {'n_estimators':[100,200,300,400,500], \n",
    "                  'max_depth': [10,12,14,16,18] }\n",
    "\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestRegressor(), param_grid_rf, refit = True, cv = 5, verbose = 3, n_jobs=-1) \n",
    "grid_rf.fit(X_dev, y_dev)\n",
    "\n",
    "\n",
    "rfr = RandomForestRegressor(max_depth = grid_rf.best_params_['max_depth'], \n",
    "                            n_estimators = grid_rf.best_params_['n_estimators']).fit(X_train, y_train)\n",
    "\n",
    "rfr_y_test = rfr.predict(X_test)\n",
    "print('rfr_r^2:',rfr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_r^2: 0.892922479268309\n",
      "MSE: 110.63863894518883\n",
      "10.518490335841395\n"
     ]
    }
   ],
   "source": [
    "#catboost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat = CatBoostRegressor(logging_level = 'Silent').fit(X_dev, y_dev)\n",
    "cat_y_pred = cat.predict(X_test) \n",
    "\n",
    "print('cat_r^2:',cat.score(X_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test, cat_y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, cat_y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hist_r^2: 0.8820652392628447\n",
      "MSE: 121.85696234955489\n",
      "11.038884107986409\n"
     ]
    }
   ],
   "source": [
    "#HistGradientBoosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'learning_rate' : [0.05,0.1,0.15,0.2],\n",
    "        'max_depth' : [10,12,14,16,18]}\n",
    "\n",
    "hbcv=GridSearchCV(HistGradientBoostingRegressor(),param_grid=params,cv=5)\n",
    "\n",
    "hbcv.fit(X_dev,y_dev)\n",
    "hist_y_pred = hbcv.predict(X_test)\n",
    "\n",
    "print('hist_r^2:',hbcv.score(X_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test, hist_y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, hist_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_r^2: 0.8735662466747094\n",
      "MSE: 130.63860919691456\n",
      "11.429724808450752\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import re\n",
    "X_dev = X_dev.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "LGB = LGBMRegressor().fit(X_dev, y_dev)\n",
    "lgb_y_pred = LGB.predict(X_test)\n",
    "\n",
    "print('lgb_r^2:',LGB.score(X_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test, lgb_y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, lgb_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack_r^2: 0.8805685181960389\n"
     ]
    }
   ],
   "source": [
    "# ! don't run\n",
    "rf_y_pred_dev = pd.DataFrame(rfr.predict(X_dev))\n",
    "hist_y_pred_dev = pd.DataFrame(hbcv.predict(X_dev))\n",
    "cat_y_pred_dev = pd.DataFrame(cat.predict(X_dev))\n",
    "xgb_y_pred_dev = pd.DataFrame(xgbc.predict(X_dev))\n",
    "lgb_y_pred_dev = pd.DataFrame(LGB.predict(X_dev))\n",
    "\n",
    "#concat stacked dev \n",
    "df2_dev = pd.concat([rf_y_pred_dev, hist_y_pred_dev, cat_y_pred_dev, xgb_y_pred_dev, lgb_y_pred_dev], axis=1)\n",
    "df2_dev.columns = ['rf','hist','cat','xgb', 'lgb']\n",
    "\n",
    "rf_y_pred_test = pd.DataFrame(rfr.predict(X_test))\n",
    "hist_y_pred_test = pd.DataFrame(hbcv.predict(X_test))\n",
    "cat_y_pred_test = pd.DataFrame(cat.predict(X_test))\n",
    "xgb_y_pred_test = pd.DataFrame(xgbc.predict(X_test))\n",
    "lgb_y_pred_test = pd.DataFrame(LGB.predict(X_test))\n",
    "\n",
    "#concat stacked test\n",
    "df2_test=pd.concat([rf_y_pred_test, hist_y_pred_test, cat_y_pred_test, xgb_y_pred_test, lgb_y_pred_test], axis=1)\n",
    "df2_test.columns = ['rf','hist','cat','xgb', 'lgb']\n",
    "\n",
    "#construct \"mega-model\" and fit new trainging data\n",
    "\n",
    "stack_model = CatBoostRegressor(logging_level = 'Silent', random_state=42)\n",
    "stack_model.fit(df2_dev, y_dev)\n",
    "\n",
    "#predict with mega-model\n",
    "stack_y_pred = stack_model.predict(df2_test)\n",
    "\n",
    "print('stack_r^2:',stack_model.score(df2_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test, stack_y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, stack_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack_r^2: 0.8821581194070621\n",
      "MSE: 121.76099325472501\n",
      "11.034536386034757\n"
     ]
    }
   ],
   "source": [
    "# delete random forest (time consuming + poor performance)\n",
    "\n",
    "hist_y_pred_dev = pd.DataFrame(hbcv.predict(X_dev))\n",
    "cat_y_pred_dev = pd.DataFrame(cat.predict(X_dev))\n",
    "xgb_y_pred_dev = pd.DataFrame(xgbc.predict(X_dev))\n",
    "lgb_y_pred_dev = pd.DataFrame(LGB.predict(X_dev))\n",
    "\n",
    "#concat stacked dev \n",
    "df2_dev = pd.concat([hist_y_pred_dev, cat_y_pred_dev, xgb_y_pred_dev, lgb_y_pred_dev], axis=1)\n",
    "df2_dev.columns = ['hist','cat','xgb', 'lgb']\n",
    "\n",
    "hist_y_pred_test = pd.DataFrame(hbcv.predict(X_test))\n",
    "cat_y_pred_test = pd.DataFrame(cat.predict(X_test))\n",
    "xgb_y_pred_test = pd.DataFrame(xgbc.predict(X_test))\n",
    "lgb_y_pred_test = pd.DataFrame(LGB.predict(X_test))\n",
    "\n",
    "#concat stacked test\n",
    "df2_test=pd.concat([hist_y_pred_test, cat_y_pred_test, xgb_y_pred_test, lgb_y_pred_test], axis=1)\n",
    "df2_test.columns = ['hist','cat','xgb', 'lgb']\n",
    "\n",
    "#construct \"mega-model\" and fit new trainging data\n",
    "\n",
    "stack_model = CatBoostRegressor(logging_level = 'Silent', random_state=42)\n",
    "stack_model.fit(df2_dev, y_dev)\n",
    "\n",
    "#predict with mega-model\n",
    "stack_y_pred = stack_model.predict(df2_test)\n",
    "\n",
    "\n",
    "# stack_absolute_error = mean_absolute_error(y_test, stack_y_pred)\n",
    "# print('stack_absolute_error: ', stack_absolute_error)\n",
    "print('stack_r^2:',stack_model.score(df2_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test, stack_y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, stack_y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
